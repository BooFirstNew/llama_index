{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92dad89e-d84a-4d85-85e1-6beaed293605",
   "metadata": {},
   "source": [
    "# Llama Pack - Resume Screener ðŸ“„\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/examples/llama_hub/llama_pack_resume.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This example shows you how to use the Resume Screener Llama Pack.\n",
    "You can find all packs on https://llamahub.ai\n",
    "\n",
    "The resume screener is designed to analyze a candidate's resume according to a set of criteria, and decide whether the candidate is a fit for the job.\n",
    "\n",
    "in this example we'll evaluate a sample resume (e.g. Jerry's old resume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4722b0b-ff5e-4e71-990b-94ec65f8b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index llama-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221e488-0d1f-4890-b081-27530fcac5f3",
   "metadata": {},
   "source": [
    "### Setup Data\n",
    "\n",
    "We'll load some sample Wikipedia data for OpenAI, Sam, Mira, and Emmett. Why? No reason in particular :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe6c66-5107-4952-b670-e60153ff916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers import WikipediaReader\n",
    "\n",
    "loader = WikipediaReader()\n",
    "documents = loader.load_data(\n",
    "    pages=[\"OpenAI\", \"Sam Altman\", \"Mira Murati\", \"Emmett Shear\"],\n",
    "    auto_suggest=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb38b7-0235-406c-9954-ab46809eef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do sentence splitting on the first piece of text\n",
    "from llama_index.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9700e6b-525d-46e2-940d-1768a42291b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_splitter = SentenceSplitter(chunk_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d74a5e-6326-462c-a6f5-0694ad6388cb",
   "metadata": {},
   "source": [
    "We get the first chunk from each essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3539635-e328-42fa-b712-43616841c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first 1024 tokens for each entity\n",
    "openai_node = sentence_splitter.get_nodes_from_documents([documents[0]])[0]\n",
    "sama_node = sentence_splitter.get_nodes_from_documents([documents[1]])[0]\n",
    "mira_node = sentence_splitter.get_nodes_from_documents([documents[2]])[0]\n",
    "emmett_node = sentence_splitter.get_nodes_from_documents([documents[3]])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e36b8-81d9-4afa-b53b-c810fbc84627",
   "metadata": {},
   "source": [
    "We'll also download Jerry's resume in 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8aec6b-239c-45d5-a919-05cc52600fa1",
   "metadata": {},
   "source": [
    "## Download Resume Screener Pack from LlamaHub\n",
    "\n",
    "Here we download the resume screener pack class from LlamaHub.\n",
    "\n",
    "We'll use it for two use cases:\n",
    "- whether the candidate is a good fit for a front-end / full-stack engineering role.\n",
    "- whether the candidate is a good fit for the CEO of OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40792de-2518-40a2-8468-c020d0decf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llama_pack import download_llama_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1819c2-0e8c-4a55-8e4b-aa17619b25b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResumeScreenerPack = download_llama_pack(\n",
    "    \"ResumeScreenerPack\", \"./resume_screener_pack\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4d149-c862-4591-bd98-9d8f55278c7c",
   "metadata": {},
   "source": [
    "### Screen Candidate for FE / Typescript roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94efb7f-b170-4833-be2a-eb5911fed816",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_screener = ResumeScreenerPack(\n",
    "    job_description=\"We're looking to hire a front-end engineer\",\n",
    "    criteria=[\n",
    "        \"The individual needs to be experienced in front-end / React / Typescript\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db7399-d43b-4139-8809-f8f493329f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = resume_screener.run(resume_path=\"laurie_resume.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669250b-d0d0-4825-a429-c1d1c4f34ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While the candidate has extensive experience in the tech industry, including web development, their resume does not specifically mention experience with front-end development, React, or Typescript, which are the key requirements for this position.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(str(response.overall_reasoning))\n",
    "print(str(response.overall_decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57efbd93-7249-4b04-b5be-d74e5953d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = f\"\"\"\\\n",
    "We're looking to hire a CEO for OpenAI.\n",
    "\n",
    "Instead of listing a set of specific criteria, each \"criteria\" is instead a short biography of a previous CEO.\\\n",
    "\n",
    "For each criteria/bio, outline if the candidate's experience matches or surpasses that of the candidate.\n",
    "\n",
    "Also, here's a description of OpenAI from Wikipedia: \n",
    "{openai_node.get_content()}\n",
    "\"\"\"\n",
    "\n",
    "profile_strs = [\n",
    "    f\"Profile: {n.get_content()}\" for n in [sama_node, mira_node, emmett_node]\n",
    "]\n",
    "\n",
    "\n",
    "resume_screener = ResumeScreenerPack(\n",
    "    job_description=job_description, criteria=profile_strs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b0a27-f550-471d-83a3-c5b39e6def71",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = resume_screener.run(resume_path=\"laurie_resume.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35384368-bcb5-4422-a92d-1a1cf7aab853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### CRITERIA DECISION\n",
      "The candidate's experience does not match or surpass that of Samuel Harris Altman. While the candidate has extensive experience in the tech industry, including co-founding and running startups, they do not have experience as a CEO of a major organization like OpenAI or Y Combinator. Additionally, the candidate's experience is primarily technical and operational, whereas Altman's experience includes significant fundraising and investment activities.\n",
      "False\n",
      "### CRITERIA DECISION\n",
      "The candidate's experience does not match or surpass that of Mira Murati. While the candidate has held CTO and COO roles, they do not have experience as a CEO. Furthermore, the candidate's experience is primarily in web development and data science, whereas Murati's experience includes leading work on AI products like ChatGPT, Dall-E, and Codex.\n",
      "False\n",
      "### CRITERIA DECISION\n",
      "The candidate's experience does not match or surpass that of Emmett Shear. While the candidate has co-founded and run startups, they do not have experience as a CEO of a major organization like Twitch or OpenAI. Additionally, Shear's experience includes significant work in live video platforms and investor activities, which the candidate does not have.\n",
      "False\n",
      "#### OVERALL REASONING ##### \n",
      "While the candidate has a strong background in tech startups, web development, and data science, their experience does not match or surpass the experience of the previous CEOs in terms of leadership roles, AI product development, and investor activities.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for cd in response.criteria_decisions:\n",
    "    print(\"### CRITERIA DECISION\")\n",
    "    print(cd.reasoning)\n",
    "    print(cd.decision)\n",
    "print(\"#### OVERALL REASONING ##### \")\n",
    "print(str(response.overall_reasoning))\n",
    "print(str(response.overall_decision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3fd5c5-8a80-43e7-bb77-384a831500c5",
   "metadata": {},
   "source": [
    "### Download and Initialize Pack\n",
    "\n",
    "We use `download_llama_pack` to download the pack class, and then we initialize it with documents.\n",
    "\n",
    "Every pack will have different initialization parameters. You can find more about the initialization parameters for each pack through its [README](https://github.com/logan-markewich/llama-hub/tree/main/llama_hub/llama_packs/voyage_query_engine) (also on LlamaHub).\n",
    "\n",
    "**NOTE**: You must also specify an output directory. In this case the pack is downloaded to `voyage_pack`. This allows you to customize and make changes to the file, and import it later! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6143f5-e067-48d7-bce5-351f3a90d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llama_pack import download_llama_pack\n",
    "\n",
    "VoyageQueryEnginePack = download_llama_pack(\n",
    "    \"VoyageQueryEnginePack\", \"./voyage_pack\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a790c-1a24-478f-8af7-d23218ac80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "voyage_pack = VoyageQueryEnginePack(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f318e-5494-4650-89ef-bd1ad01785c3",
   "metadata": {},
   "source": [
    "### Inspect Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c4f33-e268-4cba-87e7-f97df78a3906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm': OpenAI(callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x11fdaae90>, model='gpt-4', temperature=0.1, max_tokens=None, additional_kwargs={}, max_retries=3, timeout=60.0, api_key='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', api_base='https://api.openai.com/v1', api_version=''),\n",
       " 'index': <llama_index.indices.vector_store.base.VectorStoreIndex at 0x2bccb3b50>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modules = voyage_pack.get_modules()\n",
    "display(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a10f2-5cbc-4ce1-94a3-68f26b4617c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = modules[\"llm\"]\n",
    "vector_index = modules[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13678e7e-77e4-4968-bfd1-73548bb05687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out LLM\n",
    "response = llm.complete(\"hello world\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca42144-2981-4000-819b-b445aa740dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out retriever\n",
    "retriever = vector_index.as_retriever()\n",
    "results = retriever.retrieve(\"What did the author do growing up?\")\n",
    "print(str(results[0].get_content()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527d037-1ffb-4880-a9ee-844b71ded0eb",
   "metadata": {},
   "source": [
    "### Run Pack\n",
    "\n",
    "Every pack has a `run` function that will accomplish a certain task out of the box. Here we will go through the full RAG pipeline with VoyageAI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6c015-afd0-42e2-99cf-33caa19a4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will run the full pack\n",
    "response = voyage_pack.run(\n",
    "    \"What did the author do growing up?\", similarity_top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c354e-8ddf-4a95-81f7-477b18d5a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author spent his time outside of school mainly writing and programming. He wrote short stories and attempted to write programs on an IBM 1401. Later, he started programming on a TRS-80, creating simple games and a word processor. He also painted still lives while studying at the Accademia.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa894b8-4236-4dd7-a2a9-6d26dacfda25",
   "metadata": {},
   "source": [
    "### Try Customizing Pack\n",
    "\n",
    "A major feature of LlamaPacks is that you can and should inspect and modify the code templates!\n",
    "\n",
    "In this example we'll show how to customize the template with a different LLM, while keeping Voyage embeddings, and then re-use it. We'll use Anthropic instead.\n",
    "\n",
    "Let's go into `voyage_pack` and create a copy.\n",
    "\n",
    "1. For demo purposes we'll copy `voyage_pack` into `voyage_pack_copy`.\n",
    "2. Go into `voyage_pack_copy/base.py` and look at the `VoyageQueryEnginePack` class definition. This is where all the core logic lives. As you can see the pack class itself is a very light base abstraction. You're free to copy/paste the code as you wish.\n",
    "3. Go into the line in the `__init__` where it do `llm = OpenAI(model=\"gpt-4\")` and instead change it to `llm = Anthropic()` (which defaults to claude-2).\n",
    "4. Do `from llama_index.llms import Anthropic` and ensure that `ANTHROPIC_API_KEY` is set in your env variable.\n",
    "5. Now you can use!\n",
    "\n",
    "In the below sections we'll directly re-import the modified `VoyageQueryEnginePack` and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d236f8d-ab5a-41f3-895b-36c897d5646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from voyage_pack_copy.base import VoyageQueryEnginePack\n",
    "\n",
    "voyage_pack = VoyageQueryEnginePack(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464fd989-f253-428d-8b5a-ee59d5a30df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unfortunately I do not have enough context in the provided information to definitively state what the author did during his time at RISD. The passage mentions that he learned a lot in a color class he took there, that he was basically teaching himself to paint, and that in 1993 he dropped out. But there are no specific details provided about his activities or course of study during his time enrolled at RISD. I apologize that I cannot provide a more complete response.\n"
     ]
    }
   ],
   "source": [
    "response = voyage_pack.run(\"What did the author do during his time in RISD?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
